# 第十节课代码

# 会话维持

  ### 会话误区：cookie误区

import requests

requests.get('http://httpbin.org/cookies/set/number/123456')
response=requests.get('http://httpbin.org/cookies')
print(response.text)

```
{"cookies":{}}
```

## 产生无法获取到cookies的原因是由于上两次get实质上是类似于两个浏览器的访问，因此，第二个浏览器无法获得第一个浏览器所存的cookies

import requests

s=requests.Session()#通过声明Session告诉两次用的是一个浏览器
s.get('http://httpbin.org/cookies/set/number/123456')
response=s.get('http://httpbin.org/cookies')
print(response.text)

```
{"cookies":{"number":"123456"}}
```

# 证书验证（ssl证书）

# ‘http://www.12306.cn'

# from requests.packages import urllib3

# urllib3.disable_warnings()

# verify(验证)=False

import requests
from requests.packages import urllib3
urllib3.disable_warnings() #忽略警告信息，因为没有ssl证书，浏览器会返回一个让你添加ssl证书的信息，只有在证书不被官方认可的情况下，才会弹出，此时才需要忽略
response=requests.get('https://www.12306.cn',verify=False)#是否校验verify
print(response.status_code)

```
200
```

# 本地设置ssl证书







# 一般反爬虫措施：

# 代理，构建代理池

代理类型：HTTP;HTTPS

import requests
proxies={'http':'http://121.196.218.197:3128',
        'https':'http://121.196.218.197:3128'}
response=requests.get('https://www.baidu.com',proxies=proxies)
print(response.status_code)

```
200
```



# 设置超时时间：timeout=1

import requests
response = requests.get('http://www.baidu.com',timeout=1)
print(response.status_code)

```
200
```

如果请求超时，不想代码断掉重新开始，就用try

# 处理错误

# ReadTimeout链接超时

# ConnectionError链接错误

# RequestException请求错误

